## 分布式背景
- 含义：
    - 把爬虫部署在多台电脑主机上，并且互相之间还有通讯的一种爬虫技术
    - 在多台主机上同时运行爬虫任务，共享一个队列（爬虫请求地址队列）， 这个队列需要去重。从技术的角度在考虑，这个队列用redis是最高效的。
- 为何用分布式：
    - 其实大多数爬虫在编写的时候如果遇到效率问题，用多进程，协程就可以满足需求了，但是当一个爬虫类的项目上升到非常大的级别或者达到商用的目的，
      你需要同时抓取成千上万个网站，处理上亿的请求（有点夸张了），单个的爬虫非常难实现这样的需求，就需要大量的服务器进行同时分布抓取，
      所以你看到大多数分布式爬虫课程到最后都是在模拟一个搜索引擎，因为搜索引擎就是一个超级爬虫。

## 分布式爬虫框架      
### 1、scrapy-redis
- 【参考】https://blog.csdn.net/hihell/article/details/107066454
- 简介：scrapy-redis 是基于redis的一个scrapy组件，它重构了原scrapy的scheduler调度方式，改造了collection.deque，
        将scrapy queue 换成了redis数据库，在同一个redis-server（redis服务器）中存放要爬取的request（请求地址），
        然后让多个spider（爬虫程序）去同一个redis-server中读取，调度器对新的request（请求地址）进行入队列操作，然后重复的推进下去。
- 优点：对于分布式爬虫，scrapy-redis 目前是应用最多的，并且是互联网相关教程说明最多的，原因也不用太深究，
       综合各种因素来看该框架是最简单的构建分布式爬虫的方式，而且资料全。
- 使用：
    - 实现： ./small_spider/scrapy1/distributed_crawl
    - slave（仆）机器们各自执行项目代码（scrapy runspider命令）
    - master（主）机器，只需要执行 lpush 命令
  