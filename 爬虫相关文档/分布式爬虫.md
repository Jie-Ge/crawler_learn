## 分布式背景
- 含义：
    - 把爬虫部署在多台电脑主机上，并且互相之间还有通讯的一种爬虫技术
    - 在多台主机上同时运行爬虫任务，共享一个队列（爬虫请求地址队列）， 这个队列需要去重。从技术的角度在考虑，这个队列用redis是最高效的。
- 为何用分布式：
    - 其实大多数爬虫在编写的时候如果遇到效率问题，用多进程，协程就可以满足需求了，但是当一个爬虫类的项目上升到非常大的级别或者达到商用的目的，
      你需要同时抓取成千上万个网站，处理上亿的请求（有点夸张了），单个的爬虫非常难实现这样的需求，就需要大量的服务器进行同时分布抓取，
      所以你看到大多数分布式爬虫课程到最后都是在模拟一个搜索引擎，因为搜索引擎就是一个超级爬虫。

## 分布式爬虫框架      
### 1、scrapy-redis
- 【参考】https://blog.csdn.net/hihell/article/details/107066454
- 简介：scrapy-redis 是基于redis的一个scrapy组件，它重构了原scrapy的scheduler调度方式，改造了collection.deque，
        将scrapy queue 换成了redis数据库，在同一个redis-server（redis服务器）中存放要爬取的request（请求地址），
        然后让多个spider（爬虫程序）去同一个redis-server中读取，调度器对新的request（请求地址）进行入队列操作，然后重复的推进下去。
        数据提交到scrapy_redis提供的可以被共享的redis管道中（也即存到redis中）（而不是scrapy原生的管道中）
- 优点：对于分布式爬虫，scrapy-redis 目前是应用最多的，并且是互联网相关教程说明最多的，原因也不用太深究，
       综合各种因素来看该框架是最简单的构建分布式爬虫的方式，而且资料全。
- 缺点：缺点：scrapy-redis调度的任务是Request对象，里面信息量比较大（不仅包含url，还有callback函数、headers等信息），
        导致的结果就是会降低爬虫速度、而且会占用Redis大量的存储空间。当然我们可以重写方法实现调度url
- 使用：
    - 实现： 
        - 1）small_spider/scrapy1/distributed_crawl
        - 2）100例中例73
    - 相关操作：small_spider/scrapy1/scrapy的基本使用.md
    - slave（仆）机器们各自执行项目代码（scrapy runspider命令）
    - master（主）机器，只需要执行 lpush 命令
- Redis Desktop Manager
    - redis的桌面工具,可以图形化界面操作redis数据库
- 遇到的问题
    - 1）写了一个最简单的分布式爬虫，执行项目始终没有调用 parse() 方法
        - 解决：查看RedisCrawlSpider类文件，文件中添加 parse() 方法【可从scrapy中复制，防止出错】
        - 但是，github上的源码也没有，而且添加了之后，在 '基于CrawlSpider的全站数据' 分布式爬取的时候会出错（不添加就正常）