## 分布式背景
- 含义：
    - 把爬虫部署在多台电脑主机上，并且互相之间还有通讯的一种爬虫技术
    - 在多台主机上同时运行爬虫任务，共享一个队列（爬虫请求地址队列）， 这个队列需要去重。从技术的角度在考虑，这个队列用redis是最高效的。
- 为何用分布式：
    - 其实大多数爬虫在编写的时候如果遇到效率问题，用多进程，协程就可以满足需求了，但是当一个爬虫类的项目上升到非常大的级别或者达到商用的目的，
      你需要同时抓取成千上万个网站，处理上亿的请求（有点夸张了），单个的爬虫非常难实现这样的需求，就需要大量的服务器进行同时分布抓取，
      所以你看到大多数分布式爬虫课程到最后都是在模拟一个搜索引擎，因为搜索引擎就是一个超级爬虫。

## 分布式爬虫框架      
### 1、scrapy-redis
- 【参考】https://blog.csdn.net/hihell/article/details/107066454
- 简介：scrapy-redis 是基于redis的一个scrapy组件，它重构了原scrapy的scheduler调度方式，改造了collection.deque，
        将scrapy queue 换成了redis数据库，在同一个redis-server（redis服务器）中存放要爬取的request（请求地址），
        然后让多个spider（爬虫程序）去同一个redis-server中读取，调度器对新的request（请求地址）进行入队列操作，然后重复的推进下去。
        数据提交到scrapy_redis提供的可以被共享的redis管道中（也即存到redis中）（而不是scrapy原生的管道中）
- 优点：
    - 对于分布式爬虫，scrapy-redis 目前是应用最多的，并且是互联网相关教程说明最多的，原因也不用太深究，
      综合各种因素来看该框架是最简单的构建分布式爬虫的方式，而且资料全。
    - scrapy_redis通过redis实现调度器的队列和指纹集合，完成分布式和去重。
- 缺点：scrapy-redis调度的任务是Request对象，里面信息量比较大（不仅包含url，还有callback函数、headers等信息），
        导致的结果就是会降低爬虫速度、而且会占用Redis大量的存储空间。当然我们可以重写方法实现调度url
- 使用：
    - 实现： 
        - 1）small_spider/scrapy1/distributed_crawl
        - 2）100例中例73
    - 相关操作：small_spider/scrapy1/scrapy的基本使用.md
    - slave（仆）机器们各自执行项目代码（scrapy runspider命令）
    - master（主）机器，只需要执行 lpush 命令
- Redis Desktop Manager
    - redis的桌面工具,可以图形化界面操作redis数据库
- 遇到的问题
    - 1）写了一个最简单的分布式爬虫，执行项目始终没有调用 parse() 方法
        - 解决：查看RedisCrawlSpider类文件，文件中添加 parse() 方法【可从scrapy中复制，防止出错】
        - 但是，github上的源码也没有，而且添加了之后，在 '基于CrawlSpider的全站数据' 分布式爬取的时候会出错（不添加就正常）
    
### 2、celery
- 【参考】https://blog.csdn.net/hihell/article/details/107387305  
        https://blog.csdn.net/weixin_44799217/article/details/111666885  
  【使用手册】http://docs.jinkan.org/docs/celery/  
  【中文使用手册】https://www.celerycn.io/yong-hu-zhi-nan/tiao-yong-ren-wu-calling-tasks
  
- 简介：Celery是一个简单、灵活且可靠的，处理大量消息的分布式任务队列框架，专注于实时处理的异步任务队列，同时也支持任务调度；  
       核心就是通过队列来实现 跨线程 或者 跨终端 进行作业分发；  
       Celery的架构由三部分组成，消息队列（brokers），任务执行单元（消费者、workers）和任务执行结果存储（backend）组成。
- 应用场景
    - 耗时的操作，耗时的操作交由Celery去异步执行，比如发送邮件、短信、消息推送、音视频处理等
    - 定时任务
    - 有延时需要网络IO的（耗时），并且不关心返回结果的数据（会自行保存结果，过一段时间只需要拿着任务id就可以拿到任务执行结果）
- 特点：
    - 简单：使用简单，用户无需进行复杂的配置即可快速的定义一个分布式任务。
    - 高可用：在连接中断或者失败的情况下，worker和客户端有重试机制保证任务得到执行。
    - 高效：一个Celery进程能够在一分钟内处理上百万个任务，这是因为使用协程机制可以大大减小资源消耗。
    - 灵活：Celery基于一些定义良好的协议实现，几乎每个组件都可以自定义拓展
- 缺点：
    - 这个库在真实的使用中存在不少的问题，而且国内使用的比较少
    - celery3.1.25 之后，由于缺乏资金已经不支持windows了，若想支持，还需安装其他模块
- 安装：
    - 包安装：`pip install selery` 
        - 【需要注意在windows上，注意celery版本、python版本】
        - celery3.1.25 之后，由于缺乏资金已经不支持windows了，若想支持，还需安装其他模块
    - redis安装
- 使用
    - 开启redis服务
    - 创建文件【100例 例75】
        - spider_worker.py  任务执行单元（消费者、workers），监控broker队列，有新作业即执行
        - celeryconfig.py   配置文件
        - add_task.py       任务加入到 broker 队列中，以便刚才我们创建的 worker 能够从队列中取出任务并执行
        - task_run.py       调用任务
    - 命令行先把worker运行起来： 
        - `celery -A spider_worker worker -l info`
        - or `celery worker -A spider_worker --loglevel=info --concurrency=5`
            - '-A' : Celery实例所在的文件
            - 'worker' : 表示以 worker 方式运行，其他方式可以自行查阅文档
            - '-l info' :  表示结点的日志登记是 info
            - ”loglevel” 指定了日志等级， 默认为warning。
            - ”concurrency” 指定最大并发数，默认为CPU核数。
    - 然后再直接 Run task_run.py
    - 有些注释在案例中